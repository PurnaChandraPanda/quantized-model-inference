{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import (\n",
    "    AmlCompute, Model, Environment, CodeConfiguration, \n",
    "    ManagedOnlineEndpoint, ManagedOnlineDeployment, OnlineRequestSettings, ProbeSettings\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "import time, sys, json, os\n",
    "from IPython.display import display, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "\n",
    "workspace_ml_client = MLClient.from_config(\n",
    "    credential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf/models' 'https://mlws012181044126.blob.core.windows.net/azureml-blobstore-b81b1c5e-0151-42cf-9c96-ad079150a5ee/LocalUpload/f41ffe73a047bcb05789509cc20371db/models' \n",
      "\n",
      "See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'tinyllama-gguf', 'description': 'tinyllamagguf - gguf format model', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/providers/Microsoft.MachineLearningServices/workspaces/mlws01/models/tinyllama-gguf/versions/3', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fc12d327b80>, 'serialize': <msrest.serialization.Serializer object at 0x7fc12d38b370>, 'version': '3', 'latest_version': None, 'path': 'azureml://subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/workspaces/mlws01/datastores/workspaceblobstore/paths/LocalUpload/f41ffe73a047bcb05789509cc20371db/models', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': 'Development'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the foundation model from local as Model asset in ml workspace\n",
    "model = Model(\n",
    "    path=\"models\",\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=\"tinyllama-gguf\",\n",
    "    description=\"tinyllamagguf - gguf format model\",\n",
    ")\n",
    "\n",
    "workspace_ml_client.create_or_update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading env (0.0 MBs): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 847/847 [00:00<00:00, 102176.52it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'tinyllama-gguf-env', 'description': 'Custom environment with additional dependencies', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/providers/Microsoft.MachineLearningServices/workspaces/mlws01/environments/tinyllama-gguf-env/versions/14', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fc12d3bc460>, 'serialize': <msrest.serialization.Serializer object at 0x7fc12d38b550>, 'version': '14', 'conda_file': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7fc12d38b3a0>, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "# Create a new environment based on the curated one\n",
    "custom_env = Environment(\n",
    "    name=\"tinyllama-gguf-env\",\n",
    "    description=\"Custom environment with additional dependencies\",\n",
    "    build=BuildContext(path=\"../env\")\n",
    ")\n",
    "\n",
    "# Register the custom environment\n",
    "workspace_ml_client.environments.create_or_update(custom_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "online_endpoint_name = \"tinyllama-gguf-ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for tinyllama gguf\",\n",
    "    auth_mode=\"key\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed endpoint create async call\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = \"deploy01\"\n",
    "model = \"tinyllama-gguf@latest\"\n",
    "env = \"tinyllama-gguf-env@latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed endpoint deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../onlinescoring\",\n",
    "        scoring_script=\"score.py\",\n",
    "    ),\n",
    "    instance_type=\"Standard_F16s_v2\",\n",
    "    instance_count=1,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        request_timeout_ms=120000,\n",
    "    ),\n",
    "    liveness_probe=ProbeSettings(\n",
    "        initial_delay=600\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint tinyllama-gguf-ep exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading onlinescoring (0.02 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19826/19826 [00:00<00:00, 182064.79it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................................."
     ]
    }
   ],
   "source": [
    "# managed endpoint deplyment create async call\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(deployment=demo_deployment).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://tinyllama-gguf-ep.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://tinyllama-gguf-ep.eastus2.inference.ml.azure.com/swagger.json', 'name': 'tinyllama-gguf-ep', 'description': 'Online endpoint for tinyllama gguf', 'tags': {}, 'properties': {'createdBy': 'Purna Chandra Panda', 'createdAt': '2024-12-23T03:32:43.436805+0000', 'lastModifiedAt': '2024-12-23T03:32:43.436805+0000', 'azureml.onlineendpointid': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourcegroups/rg-mlws/providers/microsoft.machinelearningservices/workspaces/mlws01/onlineendpoints/tinyllama-gguf-ep', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:b81b1c5e-0151-42cf-9c96-ad079150a5ee:3023fd76-3efc-48f0-995b-af942cb6d3fa?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/providers/Microsoft.MachineLearningServices/workspaces/mlws01/onlineEndpoints/tinyllama-gguf-ep', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fc12d409300>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fc13d452620>, 'traffic': {'deploy01': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update traffic to the deployment for 100%\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test endpoint with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"output\": \"1. The Eiffel Tower\\n2. Notre-Dame Cathedral\\n3. Palace of Versailles\\n4. Le Louvre Museum\\n5. Champs-\\u00c9lys\\u00e9es\\n6. Arc de Triomphe\\n7. Sacr\\u00e9-C\\u0153ur Basilica\\n8. Luxembourg Gardens\\n9. Jardin des Plantes\\n10. The Marais Poissoneries\\n\\nI hope this helps you plan your trip to Paris! Let me know if there's anything else I can help with.\"}\n"
     ]
    }
   ],
   "source": [
    "# score the request file using the online endpoint with the azureml endpoint invoke method\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"../payload/request1.json\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"output\": \"The capital of India is New Delhi.\"}\n"
     ]
    }
   ],
   "source": [
    "# score the request file using the online endpoint with the azureml endpoint invoke method\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"../payload/request3.json\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
