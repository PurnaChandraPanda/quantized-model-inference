{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import (\n",
    "    AmlCompute, Model, Environment, CodeConfiguration, \n",
    "    ManagedOnlineEndpoint, ManagedOnlineDeployment, OnlineRequestSettings, ProbeSettings\n",
    ")\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "import time, sys, json, os\n",
    "from IPython.display import display, JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: /config.json\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "\n",
    "workspace_ml_client = MLClient.from_config(\n",
    "    credential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
      "\n",
      "Example: azcopy copy '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf/models' 'https://mlws012181044126.blob.core.windows.net/azureml-blobstore-b81b1c5e-0151-42cf-9c96-ad079150a5ee/LocalUpload/f41ffe73a047bcb05789509cc20371db/models' \n",
      "\n",
      "See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'tinyllama-gguf', 'description': 'tinyllamagguf - gguf format model', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/providers/Microsoft.MachineLearningServices/workspaces/mlws01/models/tinyllama-gguf/versions/2', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7ff4142f5120>, 'serialize': <msrest.serialization.Serializer object at 0x7ff4142f56c0>, 'version': '2', 'latest_version': None, 'path': 'azureml://subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/workspaces/mlws01/datastores/workspaceblobstore/paths/LocalUpload/f41ffe73a047bcb05789509cc20371db/models', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model', 'stage': 'Development'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# register the foundation model from local as Model asset in ml workspace\n",
    "model = Model(\n",
    "    path=\"models\",\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=\"tinyllama-gguf\",\n",
    "    description=\"tinyllamagguf - gguf format model\",\n",
    ")\n",
    "\n",
    "workspace_ml_client.create_or_update(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Environment({'arm_type': 'environment_version', 'latest_version': None, 'image': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'tinyllama-gguf-env', 'description': 'Custom environment with additional dependencies', 'tags': {}, 'properties': {'azureml.labels': 'latest'}, 'print_as_yaml': False, 'id': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/providers/Microsoft.MachineLearningServices/workspaces/mlws01/environments/tinyllama-gguf-env/versions/13', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7ff40363af80>, 'serialize': <msrest.serialization.Serializer object at 0x7ff40363ac20>, 'version': '13', 'conda_file': None, 'build': <azure.ai.ml.entities._assets.environment.BuildContext object at 0x7ff40363af50>, 'inference_config': None, 'os_type': 'Linux', 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "\n",
    "# Create a new environment based on the curated one\n",
    "custom_env = Environment(\n",
    "    name=\"tinyllama-gguf-env\",\n",
    "    description=\"Custom environment with additional dependencies\",\n",
    "    build=BuildContext(path=\"../env\")\n",
    ")\n",
    "\n",
    "# Register the custom environment\n",
    "workspace_ml_client.environments.create_or_update(custom_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create online endpoint - endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "online_endpoint_name = \"tinyllama-gguf-ep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"Online endpoint for tinyllama gguf\",\n",
    "    auth_mode=\"key\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed endpoint create async call\n",
    "workspace_ml_client.begin_create_or_update(endpoint).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = \"deploy01\"\n",
    "model = \"tinyllama-gguf@latest\"\n",
    "env = \"tinyllama-gguf-env@latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managed endpoint deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    environment=env,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../onlinescoring\",\n",
    "        scoring_script=\"score.py\",\n",
    "    ),\n",
    "    instance_type=\"Standard_F16s_v2\",\n",
    "    instance_count=1,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        request_timeout_ms=120000,\n",
    "    ),\n",
    "    liveness_probe=ProbeSettings(\n",
    "        initial_delay=600\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check: endpoint tinyllama-gguf-ep exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "# managed endpoint deplyment create async call\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(deployment=demo_deployment).wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://tinyllama-gguf-ep.eastus2.inference.ml.azure.com/score', 'openapi_uri': 'https://tinyllama-gguf-ep.eastus2.inference.ml.azure.com/swagger.json', 'name': 'tinyllama-gguf-ep', 'description': 'Online endpoint for tinyllama gguf', 'tags': {}, 'properties': {'createdBy': 'Purna Chandra Panda', 'createdAt': '2024-12-09T05:27:42.495816+0000', 'lastModifiedAt': '2024-12-09T05:27:42.495816+0000', 'azureml.onlineendpointid': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourcegroups/rg-mlws/providers/microsoft.machinelearningservices/workspaces/mlws01/onlineendpoints/tinyllama-gguf-ep', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/providers/Microsoft.MachineLearningServices/locations/eastus2/mfeOperationsStatus/oeidp:b81b1c5e-0151-42cf-9c96-ad079150a5ee:cda78338-2452-4959-8038-9b7fa177943f?api-version=2022-02-01-preview'}, 'print_as_yaml': False, 'id': '/subscriptions/6977e295-0d7c-4557-8e0b-26e2f6532103/resourceGroups/rg-mlws/providers/Microsoft.MachineLearningServices/workspaces/mlws01/onlineEndpoints/tinyllama-gguf-ep', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpuds11001/code/Users/pupanda/gpt-use-case/foundation-models/quantized-model-inference/inference-tinyllama1.1b-gguf', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7ff41432a530>, 'auth_mode': 'key', 'location': 'eastus2', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7ff427bcfd00>, 'traffic': {'deploy01': 100}, 'mirror_traffic': {}, 'kind': 'Managed'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update traffic to the deployment for 100%\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test endpoint with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"output\": \"1. Champs-Elys\\u00e9es\\n2. Eiffel Tower\\n3. Notre Dame Cathedral\\n4. Arc de Triomphe\\n5. Louvre Museum\\n6. Giverny Garden\\n7. The Seine River\\n8. Montmartre\\n9. Jardin des Plantes\\n10. Mus\\u00e9e d'Orsay\\n\\nRemember to always check the weather and safety rules before visiting these places, especially if you plan on seeing any landmarks or monuments.\"}\n"
     ]
    }
   ],
   "source": [
    "# score the request file using the online endpoint with the azureml endpoint invoke method\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"../payload/request1.json\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"output\": \"The capital of India is New Delhi.\"}\n"
     ]
    }
   ],
   "source": [
    "# score the request file using the online endpoint with the azureml endpoint invoke method\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"../payload/request3.json\",\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
